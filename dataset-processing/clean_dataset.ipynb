{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e400359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7399a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../resources/mp16_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a01b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _check_one(session, url, timeout=8):\n",
    "    if not isinstance(url, str) or url.strip() == \"\":\n",
    "        return False\n",
    "    try:\n",
    "        async with session.head(url, allow_redirects=True, timeout=timeout) as r:\n",
    "            if r.status == 200:\n",
    "                return True\n",
    "            if r.status in (405, 501) or r.status >= 400:\n",
    "                # fallback to small GET\n",
    "                async with session.get(url, timeout=timeout) as r2:\n",
    "                    return 200 <= r2.status < 400\n",
    "            return False\n",
    "    except Exception:\n",
    "        try:\n",
    "            async with session.get(url, timeout=timeout) as r3:\n",
    "                return 200 <= r3.status < 400\n",
    "        except Exception:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9685c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def filter_alive_async(urls, concurrency, timeout=8):\n",
    "    connector = aiohttp.TCPConnector(limit=concurrency, force_close=False)\n",
    "    timeout_obj = aiohttp.ClientTimeout(total=None, sock_connect=timeout, sock_read=timeout)\n",
    "    async with aiohttp.ClientSession(connector=connector, timeout=timeout_obj) as session:\n",
    "        sem = asyncio.Semaphore(concurrency)\n",
    "        async def guarded(u):\n",
    "            async with sem:\n",
    "                return await _check_one(session, u, timeout=timeout)\n",
    "        tasks = [guarded(u) for u in urls]\n",
    "        # tqdm over asyncio tasks\n",
    "        results = []\n",
    "        for coro in tqdm_asyncio.as_completed(tasks, total=len(tasks), desc=\"Checking URLs\"):\n",
    "            res = await coro\n",
    "            results.append(res)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b446ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking URLs: 100%|██████████| 4122119/4122119 [2:54:17<00:00, 394.19it/s]  \n"
     ]
    }
   ],
   "source": [
    "urls = df_train['URL'].fillna(\"\").astype(str).tolist()\n",
    "alive_mask = await filter_alive_async(urls, concurrency=200, timeout=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dad729e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kept 3784539 rows, removed 337580 rows\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_train[pd.Series(alive_mask, index=df_train.index)].reset_index(drop=True)\n",
    "df_dead = df_train[~pd.Series(alive_mask, index=df_train.index)].reset_index(drop=True)\n",
    "print(f\"kept {len(df_clean)} rows, removed {len(df_dead)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa793a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../resources/gadm_split_2.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040bd5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows kept inside polygons: 3635097; removed (outside polygons): 149442\n"
     ]
    }
   ],
   "source": [
    "pts = gpd.GeoDataFrame(\n",
    "    df_clean,\n",
    "    geometry=[Point(xy) for xy in zip(df_clean['LON'], df_clean['LAT'])],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "joined = gpd.sjoin(pts, gdf[['geometry']], how='inner', predicate='within')\n",
    "\n",
    "total = len(df_clean)\n",
    "df_clean = df_clean.loc[joined.index].reset_index(drop=True)\n",
    "kept = len(df_clean)\n",
    "removed = total-kept\n",
    "print(f\"Rows kept inside polygons: {kept}; removed (outside polygons): {removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35659eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: A geo-tagged image taken in Shinagawa, Japan. This image was taken indoors. This image was taken in a urban setting. The climate is Temperate, no dry season, hot summer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://farm6.staticflickr.com/5136/5421498684_801bc01b3f.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_row = df_clean[df_clean['Prob_indoor'] > 0.95].sample(n=1).iloc[0]\n",
    "\n",
    "caption = random_row['caption']\n",
    "image_url = random_row['URL']\n",
    "\n",
    "print(\"Caption:\", caption)\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f16176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['Prob_indoor'] < 0.95].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98f456b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('../resources/mp16_combined_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
